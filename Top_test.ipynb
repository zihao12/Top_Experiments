{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../code/')\n",
    "import Top\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(12345)\n",
    "np.random.seed(12345)\n",
    "\n",
    "n = 1500\n",
    "p = 1000\n",
    "N = 1500\n",
    "K = 30\n",
    "Xi = 1/p\n",
    "Ik_card = int(p/100)\n",
    "\n",
    "\n",
    "## generate W\n",
    "W = np.zeros(shape = [K,n])\n",
    "for c in range(n):\n",
    "    S = np.random.randint(1,np.floor(K/3),1)[0]    \n",
    "    entry = np.random.uniform(0,1,S)\n",
    "    entry_indx = random.sample(range(K),k = S)\n",
    "    for en,ind in zip(entry,entry_indx):\n",
    "        W[ind,c] = en\n",
    "    W[:,c] = W[:,c]/W[:,c].sum()\n",
    "    \n",
    "\n",
    "\n",
    "## get I and its partition\n",
    "voc_indx = [x for x in range(p)]\n",
    "random.shuffle(voc_indx)\n",
    "voc_anchor = voc_indx[:K*Ik_card]\n",
    "voc_nonanchor = voc_indx[K*Ik_card+1:]\n",
    "\n",
    "voc_anchor = np.asarray(voc_anchor).reshape(Ik_card,K)\n",
    "\n",
    "## generate A\n",
    "A = np.zeros(shape=[p,K])\n",
    "for k in range(K):\n",
    "    A[voc_anchor[:,k],k] = [K*Xi]*Ik_card\n",
    "    A[voc_nonanchor,k] = np.random.uniform(0,1,len(voc_nonanchor))\n",
    "    A[voc_nonanchor,k] /= A[voc_nonanchor,k].sum()\n",
    "    A[voc_nonanchor,k] *= 1-sum(A[voc_indx[:K*Ik_card],k])\n",
    "    #A[voc_nonanchor,k] *= 1-sum(A[voc_anchor[:,k],k])\n",
    "    A[voc_nonanchor,k]*A[voc_nonanchor,k].sum()/(1-sum(A[voc_indx[:K*Ik_card],k]))\n",
    "\n",
    "AW = np.dot(A,W)\n",
    "\n",
    "## generate X\n",
    "X = np.zeros(shape = [p,n])\n",
    "for column in range(n):\n",
    "    X[:,column] = np.random.multinomial(N,AW[:,column])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([902]),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(X.sum(axis = 1) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run finished after 3.654646635055542\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "test = Top.Top(X)\n",
    "print(\"run finished after \" + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(test[\"K\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "K is right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "anchor_out = []\n",
    "out = np.sort(test[\"Anchor words\"])\n",
    "for i in range(len(test[\"Anchor words\"])):\n",
    "    if out[i] < 902:\n",
    "        anchor_out.append(out[i])\n",
    "    else:\n",
    "        anchor_out.append(out[i]+1)\n",
    "    \n",
    "#np.sort(test[\"Anchor words\"])\n",
    "#np.sort(anchor_out)\n",
    "#np.sort(voc_indx[:K*Ik_card])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(anchor_out) == np.sort(voc_indx[:K*Ik_card])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment: \n",
    "I have changed the X in the input (by taking out the rows that have zero sums) (actually only row 902). So after adjusting for that in fact, the anchor words are exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor groups (not finished yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[676, 357, 836, 711, 8, 393, 296, 599, 922, 861],\n",
       " [961, 133, 299, 75, 12, 397, 559, 465, 694, 154],\n",
       " [320, 416, 163, 553, 781, 206, 245, 24, 636, 478],\n",
       " [131, 453, 165, 741, 968, 973, 815, 879, 471, 27],\n",
       " [611, 746, 235, 303, 146, 341, 917, 472, 251, 30],\n",
       " [32, 578, 327, 331, 492, 846, 336, 337, 369, 543],\n",
       " [960, 579, 484, 742, 39, 363, 589, 339, 500, 152],\n",
       " [837, 107, 43, 459, 462, 816, 306, 884, 405, 954],\n",
       " [608, 642, 261, 615, 491, 155, 47, 948, 91, 446],\n",
       " [193, 98, 871, 841, 426, 779, 78, 175, 48, 431],\n",
       " [388, 805, 555, 428, 845, 686, 496, 50, 567, 475],\n",
       " [577, 772, 74, 204, 110, 307, 85, 55, 313, 255],\n",
       " [739, 934, 103, 587, 366, 623, 792, 793, 59, 732],\n",
       " [425, 108, 334, 368, 433, 976, 184, 378, 188, 62],\n",
       " [678, 717, 207, 81, 497, 342, 729, 667, 574, 863],\n",
       " [289, 457, 844, 941, 82, 819, 344, 986, 286, 479],\n",
       " [96, 516, 868, 401, 595, 533, 311, 600, 249, 699],\n",
       " [576, 864, 102, 936, 490, 271, 338, 695, 312, 250],\n",
       " [774, 263, 104, 649, 395, 939, 240, 278, 795, 445],\n",
       " [705, 834, 929, 487, 488, 112, 180, 856, 827, 413],\n",
       " [898, 964, 860, 236, 117, 374, 149, 763, 348, 991],\n",
       " [796, 808, 905, 267, 273, 913, 121, 634, 540, 126],\n",
       " [130, 679, 956, 654, 145, 625, 853, 470, 726, 668],\n",
       " [160, 164, 486, 966, 266, 140, 430, 468, 727, 890],\n",
       " [161, 811, 975, 920, 952, 248, 858, 220, 957, 639],\n",
       " [260, 708, 365, 494, 887, 178, 983, 596, 215, 955],\n",
       " [452, 229, 997, 618, 523, 556, 464, 531, 181, 315],\n",
       " [832, 449, 483, 358, 458, 906, 751, 370, 892, 189],\n",
       " [513, 706, 771, 485, 518, 946, 276, 277, 820, 191],\n",
       " [417, 897, 932, 869, 838, 716, 877, 280, 826, 891]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Anchor groups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[484, 708, 220, 679, 781, 642, 204, 967, 618, 869, 942, 863, 940,\n",
       "        236, 428, 856, 312, 808,  30, 779, 543, 191, 108, 533, 165, 962,\n",
       "        955, 923, 892, 793],\n",
       "       [961, 365, 811, 668, 163, 491, 313, 486, 464, 280, 479,  81, 774,\n",
       "        763, 567, 488, 250, 540, 251,  48, 331, 513, 977, 401, 974, 465,\n",
       "         43, 861, 907, 366],\n",
       "       [500, 887, 976, 470,  24, 949, 577, 160, 452, 417, 344, 574, 395,\n",
       "        992, 805, 827, 864, 273, 746,  98, 336, 706, 425, 249,  27, 133,\n",
       "        837,   8, 370, 103],\n",
       "       [339, 956, 858, 130, 206,  47, 110, 890, 315, 716, 289, 678, 104,\n",
       "        117, 845, 705, 576, 126, 303, 175, 846, 947, 368, 595, 131, 154,\n",
       "        306, 296, 449, 935],\n",
       "       [363, 178, 639, 853, 245,  91,  55, 266, 229, 838,  82, 717, 445,\n",
       "        149,  50, 834, 695, 267, 611, 193, 492, 820, 184, 311, 879, 299,\n",
       "        884, 676, 483, 623],\n",
       "       [579, 494, 161, 145, 320, 608, 772, 727, 523, 826, 286, 729, 278,\n",
       "        348, 555, 487, 937, 796, 235,  78, 578, 518, 433, 699, 969,  75,\n",
       "        816, 836, 189, 732],\n",
       "       [589, 260, 921, 957, 416, 615,  85, 140, 531, 877, 457, 342, 649,\n",
       "        965, 686, 930, 490, 906, 918, 841, 369, 277, 378, 516, 453,  12,\n",
       "        107, 711, 358, 587],\n",
       "       [ 39, 596, 958, 654, 553, 446, 307, 430, 181, 897, 987, 207, 263,\n",
       "        898, 496, 180, 271, 914, 472, 431, 337, 276, 188, 600, 815, 559,\n",
       "        459, 393, 458, 792],\n",
       "       [742, 215, 953, 625, 636, 261,  74, 468, 998, 891, 819, 497, 240,\n",
       "        860, 475, 413, 338, 121, 146, 426, 327, 485, 334, 868, 471, 694,\n",
       "        462, 599, 832,  59],\n",
       "       [152, 984, 248, 726, 478, 155, 255, 164, 556, 933, 844, 667, 795,\n",
       "        374, 388, 112, 102, 634, 341, 871,  32, 771,  62,  96, 741, 397,\n",
       "        405, 357, 751, 739]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
